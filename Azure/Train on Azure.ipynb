{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training DLWP on Azure with Microsoft Azure Machine Learning service\n",
    "For a reference on getting started with the Microsoft Azure Machine Learning service, refer to the [Microsoft documentation](https://docs.microsoft.com/en-us/azure/machine-learning/service/).\n",
    "\n",
    "First, let's import the core AzureML Python modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "from azureml.core import Experiment\n",
    "\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the parameters for our model run\n",
    "Here we set the directory where the dataset of predictor/target data is stored, the name of said dataset, and the name of the model to save. Tags optionally specifies some parameters for easy reference in the list of experiment runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = '/home/disk/wave2/jweyn/Data/Azure'\n",
    "predictor_file = 'cfs_6h_1979-2010_z500-th3-7-w700-pwat_NH_T2.nc'\n",
    "model_file = 'dlwp_6h_tau_z-tau-out_stagger'\n",
    "log_file = 'logs/tau_z-tau-out_stagger'\n",
    "tags = {'in': 'z-tau', 'out': 'z-tau', 'arch': 'fit', 'data': 'stagger'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create or import a workspace\n",
    "In this example, we assume a workspace already exists, but it is easy to create a workspace on-the-fly with `Workspace.create()`. Use environment variables to load sensitive information such as `subscription_id` and authentication passwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.get(\n",
    "    name='dlwp-ml-1',\n",
    "    subscription_id=os.environ.get('AZURE_SUBSCRIPTION_ID'),\n",
    "    resource_group='DLWP'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up the compute cluster\n",
    "This code, adapted from the Microsoft documentation example, checks for existing compute resources in the workspace or creates them if they do not exist. We use GPU nodes, of which there are a few choices:\n",
    "- STANDARD_NC6: Tesla K80\n",
    "- STANDARD_NC6_v2: Tesla P100\n",
    "- STANDARD_NC6_v3: Tesla V100\n",
    "- STANDARD_ND6: Tesla P40\n",
    "- STANDARD_NV6: Tesla M60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found compute target (compute-NC12)\n"
     ]
    }
   ],
   "source": [
    "# Name of the cluster\n",
    "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"compute-NC12\")\n",
    "compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n",
    "compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 2)\n",
    "\n",
    "# Set a GPU VM type\n",
    "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_NV6\")\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('found compute target (%s)' % compute_name)\n",
    "else:\n",
    "    print('creating a new compute target (%s)' % compute_name)\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\n",
    "                                                                min_nodes = compute_min_nodes, \n",
    "                                                                max_nodes = compute_max_nodes)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
    "    \n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy data to the compute cluster\n",
    "This optional step is needed if data hasn't yet been uploaded to a storage blob connected to the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ws.get_default_datastore()\n",
    "print(ds.datastore_type, ds.account_name, ds.container_name)\n",
    "\n",
    "# ds.upload(src_dir=data_directory, target_path='DLWP', overwrite=False, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'dlwp'\n",
    "\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a TensorFlow estimator\n",
    "Now we create an image for a TensorFlow estimator that will be used as the VM for the compute cluster. Azure creates a Docker image the first time this is run; in the future, it can re-use existing images to run faster. We upload all of the DLWP source code files located in the parent directory of this notebook.\n",
    "The script we pass to the job is `train_tf.py`, located in this directory. Details about the option parameters (and configurable settings for the specific run) can be seen/set there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.dnn import TensorFlow\n",
    "\n",
    "script_params = {\n",
    "    '--root-directory': ds.path('DLWP').as_mount(),\n",
    "    '--predictor-file': predictor_file,\n",
    "    '--model-file': model_file,\n",
    "    '--log-directory': log_file,\n",
    "#     '--temp-dir': '/mnt/tmp'\n",
    "}\n",
    "\n",
    "tf_est = TensorFlow(source_directory=os.path.join(os.getcwd(), os.pardir),\n",
    "                    script_params=script_params,\n",
    "                    compute_target=compute_target,\n",
    "                    entry_script=os.path.join(os.getcwd(), 'train_tf.py'),\n",
    "                    conda_packages=['scikit-learn', 'netCDF4', 'dask', 'xarray'],\n",
    "                    pip_packages=['keras'],\n",
    "                    use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit the experiment\n",
    "...and also print a summary table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>dlwp</td><td>dlwp_1556146544_56a55571</td><td>azureml.scriptrun</td><td>Queued</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/c31a4a22-148c-42a4-8c71-7426ed84587f/resourceGroups/DLWP/providers/Microsoft.MachineLearningServices/workspaces/dlwp-ml-1/experiments/dlwp/runs/dlwp_1556146544_56a55571\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: dlwp,\n",
       "Id: dlwp_1556146544_56a55571,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Queued)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = exp.submit(config=tf_est, tags=tags)\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the saved model\n",
    "...once the run is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is in 'Running' status; can't download files yet\n"
     ]
    }
   ],
   "source": [
    "if run.get_status() == 'Completed':\n",
    "    ds.download('/Users/Jojo/Temp/', prefix='DLWP/%s' % model_file)\n",
    "else:\n",
    "    print(\"model is in '%s' status; can't download files yet\" % run.get_status())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading DLWP/dlwp_6h_tau_z-tau-out_stagger.history\n",
      "Downloading DLWP/dlwp_6h_tau_z-tau-out_stagger.keras\n",
      "Downloading DLWP/dlwp_6h_tau_z-tau-out_stagger.pkl\n",
      "Downloaded DLWP/dlwp_6h_tau_z-tau-out_stagger.history, 1 files out of an estimated total of 3\n",
      "Downloaded DLWP/dlwp_6h_tau_z-tau-out_stagger.pkl, 2 files out of an estimated total of 3\n",
      "Downloaded DLWP/dlwp_6h_tau_z-tau-out_stagger.keras, 3 files out of an estimated total of 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.download('/Users/Jojo/Temp/', prefix='DLWP/%s' % 'dlwp_6h_tau_z-tau-out_stagger', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
